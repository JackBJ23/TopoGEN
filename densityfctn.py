# -*- coding: utf-8 -*-
"""densityfctn_plots.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18p-iieBVY6RxZ5soYxs6lvyeJs7LkDSW
"""

# ripser_parallel: https://giotto-ai.github.io/giotto-ph/build/html/modules/ripser_parallel.html
# bottleneck dist: https://persim.scikit-tda.org/en/latest/notebooks/distances.html

!pip3 install giotto-ph
import numpy as np
from gph import ripser_parallel

!pip install ipython

from IPython.display import Image  # to display images
import sys
!{sys.executable} -m pip install giotto-tda

# here comes our protagonist!
from gph import ripser_parallel

# Import utils
import numpy as np
from gtda.homology._utils import _postprocess_diagrams

# To generate dataset
from sklearn import datasets

# Plotting
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from plotly import graph_objects as go
from gtda.plotting import plot_diagram, plot_point_cloud

!pip3 install Cython ripser tadasets
!pip3 install persim #provides matching
#used this: https://persim.scikit-tda.org/en/latest/notebooks/distances.html
import persim
import tadasets
import ripser
#other packages:
import math
import scipy
import torch
import random

#euclidean dist for torch tensors:
def dist(point1, point2):
    return torch.sqrt(torch.sum((point2 - point1)**2))

def density(point_cloud, dgm, x, sigma):
  #sigma = 0.5 #0.5
  scale = 0.0001

  #with torch.no_grad():
  #  for i in range(len(dgm['dgms'][0])-1): tot += (dgm['dgms'][0][i][1]) ** 3

  density_x = 0 #density at x
  for i in range(len(dgm['dgms'][0])-1):
    p1, p2 = point_cloud[dgm['gens'][0][i][1]], point_cloud[dgm['gens'][0][i][2]] #pt (0,d) with d=dist(p1,p2) (euclidean dist)
    d = dist(p1, p2) #pt of pt cloud is (0,d)
    density_x += (d)**4 * torch.exp(-((d-x)/sigma)**2)

  return density_x * scale

def get_density_fctn(point_cloud, dgm, sigma):
   n = 500
   density_fctn = np.zeros((n, 2))
   xs = np.linspace(0.,30.,n)
   for i in range(n):
    density_fctn[i][0] = density(point_cloud, dgm, xs[i], sigma)
    density_fctn[i][1] = xs[i]
   return density_fctn

def get_curve(point_cloud, dgm, sigma):
  arr = get_density_fctn(point_cloud, dgm, sigma)
  #scatter_trace = go.Scatter(x=[point[0] for point in arr], y=[point[1] for point in arr], mode='markers', name='New Data')
  x_coords = [point[1] for point in arr]
  y_coords = [point[0] for point in arr]
  # Sort the points by x-coordinates for a smoother curve
  sorted_indices = np.argsort(x_coords)
  x_coords = [x_coords[i] for i in sorted_indices]
  y_coords = [y_coords[i] for i in sorted_indices]
  # Create a scatter plot trace for the new data with a smooth curve
  scatter_trace = go.Scatter(x=y_coords, y=x_coords, mode='lines', name=f'4SGDE; Ïƒ={sigma}')

  return scatter_trace

number_of_points = 128
newdata = np.zeros((number_of_points,2))
r1 = 0.5
for i in range(0,30):
  newdata[i][0] = random.uniform(-r1, r1)
  newdata[i][1] = random.uniform(-r1, r1)
for i in range(30,60):
  newdata[i][0] = random.uniform(-r1, r1)
  newdata[i][1] = random.uniform(-r1, r1)+10
for i in range(60,90):
  newdata[i][0] = random.uniform(-r1, r1)+15
  newdata[i][1] = random.uniform(-r1, r1)+15
for i in range(90,number_of_points):
  newdata[i][0] = random.uniform(-r1, r1)+5
  newdata[i][1] = random.uniform(-r1, r1)-8

point_cloud = torch.tensor(newdata, dtype=torch.float32, requires_grad=False)

dgm = ripser_parallel(newdata, maxdim=1, return_generators=True)
dgm_gtda = _postprocess_diagrams([dgm["dgms"]], "ripser", (0,), np.inf, True)[0]
fig = go.Figure(plot_diagram(dgm_gtda, homology_dimensions=(0,)))

curve_density1 = get_curve(point_cloud, dgm, 0.2)
fig.add_trace(curve_density1)
curve_density2 = get_curve(point_cloud, dgm, 0.7)
fig.add_trace(curve_density2)
curve_density3 = get_curve(point_cloud, dgm, 3.)
fig.add_trace(curve_density3)
fig.update_yaxes(range=[0, 20])
fig.show()

#plot initial point cloud:
fig = go.Figure(plot_point_cloud(point_cloud))
fig.show()
