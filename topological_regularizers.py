# -*- coding: utf-8 -*-
"""topo_regularizers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Oi1rfrumSkhsAfOMA8WT0lTz1dx_Jpti

Install packages:
"""

# ripser_parallel: https://giotto-ai.github.io/giotto-ph/build/html/modules/ripser_parallel.html
# bottleneck dist: https://persim.scikit-tda.org/en/latest/notebooks/distances.html

!pip3 install giotto-ph
import numpy as np
from gph import ripser_parallel

!pip install ipython

from IPython.display import Image  # to display images
import sys
!{sys.executable} -m pip install giotto-tda

# here comes our protagonist!
from gph import ripser_parallel

# Import utils
import numpy as np
from gtda.homology._utils import _postprocess_diagrams

# To generate dataset
from sklearn import datasets

# Plotting
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from plotly import graph_objects as go
from gtda.plotting import plot_diagram, plot_point_cloud

!pip3 install Cython ripser tadasets
!pip3 install persim #provides matching
#used this: https://persim.scikit-tda.org/en/latest/notebooks/distances.html
import persim
import tadasets
import ripser
#other packages:
import math
import scipy
import torch
import random

"""Functions needed:"""

#euclidean dist for torch tensors:
def dist(point1, point2):
    return torch.sqrt(torch.sum((point2 - point1)**2))

#euclidean dist for numpy points:
def dist_np(point1, point2):
    return np.sqrt(np.sum((point2 - point1)**2))

#supremum dist for torch tensors:
def dist_sup_tc(b1, d1, b2, d2):
    # Calculate the sup norm between points (b1, d1) and (b2, d2)
    return torch.max(torch.abs(b1 - b2), torch.abs(d1 - d2))

"""Function for getting persistence diagram (degs 0 and/or 1):"""

def get_dgm(point_cloud, deg):
  # Compute the persistence diagram without backprop
  with torch.no_grad():
        ##convert points for computing PD:
        points_np = point_cloud.numpy()
        # get PD with generators:
        dgm = ripser_parallel(points_np, maxdim=deg, return_generators=True)
  return dgm

# to plot at dgm:
def plot_dgm(dgm, deg):
  if deg==0:
    dgm_gtda = _postprocess_diagrams([dgm["dgms"]], "ripser", (0,), np.inf, True)[0]
    fig = go.Figure(plot_diagram(dgm_gtda, homology_dimensions=(0,)))
    fig.show()
  else:
    if deg==1:
      dgm_gtda = _postprocess_diagrams([dgm["dgms"]], "ripser", (0,1), np.inf, True)[0]
      fig = go.Figure(plot_diagram(dgm_gtda, homology_dimensions=(0,1)))
      fig.show()
    else:
      dgm_gtda = _postprocess_diagrams([dgm["dgms"]], "ripser", (0,1,2), np.inf, True)[0]
      fig = go.Figure(plot_diagram(dgm_gtda, homology_dimensions=(0,1,2)))
      fig.show()
  return 0

"""Push functions of degree 0 and 1:"""

#auxiliary loss when db(D,D0) (in deg0) only depends on D0 (so gradients are 0):
def push0(point_cloud, dgm): #code of compute_persistence_diagram here, but the sum is *-1 so backprop pushes points out from the diag
    p1, p2 = point_cloud[dgm['gens'][0][0][1]], point_cloud[dgm['gens'][0][0][2]]
    loss = -dist(p1, p2) #dropped here the /2. (real dist to diag is dist(p1, p2)/2.)
    for i in range(1, len(dgm['gens'][0])):
      p1, p2 = point_cloud[dgm['gens'][0][i][1]], point_cloud[dgm['gens'][0][i][2]] #pt (0,d) with d=dist(p1,p2) (euclidean dist)
      loss += -dist(p1, p2) #dist to diagonal of (0,d) is dist(p1, p2)/2.

    return loss

#auxiliary loss when db(D,D0) (in deg1) only depends on D0 (so gradients are 0):
def push1(point_cloud, dgm):
    if len(dgm['dgms'][1]==0):
      print("Error: no points in dgm of degree 1. Need to use a loss that does not use dgm of deg1, e.g. push0")
      return 0
    p1, p2, p3, p4 = point_cloud[dgm['gens'][1][0][0][0]], point_cloud[dgm['gens'][1][0][0][1]], point_cloud[dgm['gens'][1][0][0][2]], point_cloud[dgm['gens'][1][0][0][3]]
    #get the dist to diagonal:
    loss = -(dist(p3, p4)-dist(p2, p1))/2.
    for i in range(1, len(dgm['gens'][1])):
      p1, p2, p3, p4 = point_cloud[dgm['gens'][1][0][i][0]], point_cloud[dgm['gens'][1][0][i][1]], point_cloud[dgm['gens'][1][0][i][2]], point_cloud[dgm['gens'][1][0][i][3]]
      #get the dist to diagonal:
      loss += -(dist(p3, p4)-dist(p2, p1))/2.

    return loss

"""Bottleneck distance to dgm2 (fixed) with dgm of degrees 0 and 1:"""

def d_bottleneck0(point_cloud, dgm, dgm2): # got_loss=1 if got loss, =0 if loss does not depend on dgm
    got_loss = 1
    with torch.no_grad():
        distance_bottleneck, matching = persim.bottleneck(dgm['dgms'][0][:-1], dgm2['dgms'][0][:-1], matching=True)
        #find the pair that gives the max distance:
        index = np.argmax(matching[:, 2])
        i, j = int(matching[index][0]), int(matching[index][1]) #i, j: the i-th and j-th point of the dgm1, dgm2 respectively, that give the bottleneck dist.
        # (if the largest dist is point<->diagonal: i or j is -1)
        #i is the i-th pt in dgm and j is the j-th pt in dgm2 which give the bottleneck dist (i.e. it is the largest dim)
        #for the loss, need to know what is the point i (learnable), i=(distmatrix[xi,yi],distmatrix[ai,bi]) in the distance matrix for some 4 indices
        #but gen[0]
        # i is the index of a point of the PD. but (gens[i][1], gens[i][2]) is the pair of vertices of the point cloud that correspond to the point i=(0,d), with d=dist(gens[i][1]-gens[i][2])
        #get the 2 points that give the distance of the i-th pt in dgm in the 1st diagram and compute the loss:
    if i>=0:
      point1_dgm1 = point_cloud[dgm['gens'][0][i][1]]
      point2_dgm1 = point_cloud[dgm['gens'][0][i][2]]

    if i>=0 and j>=0:
      loss = torch.abs(dist(point1_dgm1, point2_dgm1) - dgm2['dgms'][0][j][1])
    else:
      if i==-1: #so the j-th point from dgm2 is matched to the diagonal -> backprop through loss would give 0 -> goal: make points further from diag
        #new_bdist = torch.abs(dist(point1_dgm2, point2_dgm2) - 0.)/2
        loss = 0
        got_loss = 0
      else: #then  j==-1, so the i-th point from dgm1 is matched to the diagonal
        loss = dist(point1_dgm1, point2_dgm1)/2.

    return loss, got_loss

def d_bottleneck1(point_cloud, dgm, dgm2): # got_loss=1 if got loss, =0 if loss does not depend on dgm
    got_loss = 1
    if len(dgm['dgms'][1])==0:
      print("error dgm")
      return 0, 0
    if len(dgm2['dgms'][1])==0:
      dgm2['dgms'][1] = [[0.,0.]]
      print("error2")
    with torch.no_grad():
        distance_bottleneck, matching = persim.bottleneck(dgm['dgms'][1], dgm2['dgms'][1], matching=True)
        #find the pair that gives the max distance:
        index = np.argmax(matching[:, 2])
        i, j = int(matching[index][0]), int(matching[index][1])

        #i is the i-th pt in dgm and j is the j-th pt in dgm2 which give the bottleneck dist (i.e. it is the largest dim)
        #for the loss, need to know what is the point i (learnable), i=(distmatrix[xi,yi],distmatrix[ai,bi]) in the distance matrix for some 4 indices
        # i is the index of a point of the PD. but (gens[i][1], gens[i][2]) is the pair of vertices of the point cloud that correspond to the point i=(0,d), with d=dist(gens[i][1]-gens[i][2])

    #get the 2 points that give the distance of the i-th pt in dgm in the 1st diagram:
    #if i>0, then the pt of dgm1 is off-diag:
    if i>=0:
      point0_dgm1 = point_cloud[dgm['gens'][1][0][i][0]]
      point1_dgm1 = point_cloud[dgm['gens'][1][0][i][1]]
      point2_dgm1 = point_cloud[dgm['gens'][1][0][i][2]]
      point3_dgm1 = point_cloud[dgm['gens'][1][0][i][3]]
      birth_dgm1 = dist(point0_dgm1, point1_dgm1)
      death_dgm1 = dist(point2_dgm1, point3_dgm1)
    #get the 2 points that give the distance of the j-th pt in dgm in the 2nd diagram:
    if j>=0:
      birth_dgm2 = dgm2['dgms'][1][j][0]
      death_dgm2 = dgm2['dgms'][1][j][1]

    if i>=0 and j>=0:
      loss = dist_sup_tc(birth_dgm1, death_dgm1, birth_dgm2, death_dgm2)
    else:
      if i==-1: #so the j-th point from dgm2 is matched to the diagonal
        loss = 0
        got_loss = 0
      else: #then j==-1, so the i-th point from dgm1 is matched to the diagonal
        loss = (death_dgm1 - birth_dgm1)/2.

    return loss, got_loss

"""Squared Reininghaus distance (dsigma) with dgm of degree 0:"""

def dist_2(a, b, c, d):
    return (a - c)**2 + (b - d)**2

#return Reininghaus kernel ksigma: (could make it slightly faster with different functions for each dgm (dgm2 does not need backpropagation)), but let it same for all dgms
def ksigma0(point_cloud, point_cloud2, dgm, dgm2): #maxdim of both dgms: 0
    sigma = 0.01
    ksigma = 0
    ## use formula for k_sigma from paper (https://arxiv.org/pdf/1412.6821.pdf):
    for i in range(len(dgm['gens'][0])):
        # pt in dgm: (0,d), d=dist(p1,p2)
        p1, p2 = point_cloud[dgm['gens'][0][i][1]], point_cloud[dgm['gens'][0][i][2]]
        d1 = dist(p1, p2)
        for j in range(len(dgm2['gens'][0])):
           #pt in dgm2: (0,d), d=dist(q1,q2)
           q1, q2 = point_cloud2[dgm2['gens'][0][j][1]], point_cloud2[dgm2['gens'][0][j][2]]
           d2 = dist(q1, q2)
           ksigma += torch.exp(-dist_2(0, d1, 0, d2)/(8*sigma)) - torch.exp(-dist_2(0, d1, d2, 0)/(8*sigma))

    ksigma *= 1/(8*3.141592*sigma)
    return ksigma

#return pseudo-distance that comes from ksigma and squared, dsigma**2:
def dsigma0(point_cloud, point_cloud2, dgm, dgm2):
    k11 = ksigma0(point_cloud, point_cloud, dgm, dgm)
    #k22 = ksigma(point_cloud2, point_cloud2)
    k12 = ksigma0(point_cloud, point_cloud2, dgm, dgm2)
    #return k11 + k22 - 2*k12
    return k11 - 2*k12 #no need of k22 since no backpropagation through it (fixed point cloud)

"""Same, but for dgm of degree 1:"""

#the only diff from ksigma (deg0) is how to take the pt of dgms (b,d) wrt the pts of the point clouds, for the backpropagation
def ksigma1(point_cloud, point_cloud2, dgm, dgm2): #maxdim of both dgms: 1
    sigma = 0.01
    if len(dgm['dgms'][1])==0 or len(dgm['dgms'][1])==0: return 0, 0

    ksigma1 = 0
    ## use formula for k_sigma from paper (https://arxiv.org/pdf/1412.6821.pdf):
    for i in range(len(dgm['gens'][1])):
        # pt in dgm: (b1,d1), with b1, d1 = dist(p2, p1), dist(dist(p3, p4)
        p1, p2, p3, p4 = point_cloud[dgm['gens'][1][0][i][0]], point_cloud[dgm['gens'][1][0][i][1]], point_cloud[dgm['gens'][1][0][i][2]], point_cloud[dgm['gens'][1][0][i][3]]
        b1 = dist(p1,p2)
        d1 = dist(p3,p4)

        for j in range(len(dgm2['gens'][1])):
          #pt in dgm2: (b2,d2)
          q1, q2, q3, q4 = point_cloud2[dgm2['gens'][1][0][j][0]], point_cloud2[dgm2['gens'][1][0][j][1]], point_cloud2[dgm2['gens'][1][0][j][2]], point_cloud2[dgm2['gens'][1][0][j][3]]
          b2 = dist(q1,q2)
          d2 = dist(q3,q4)

          ksigma1 += torch.exp(-dist_2(b1, d1, b2, d2)/(8*sigma)) - torch.exp(-dist_2(b1, d1, d2, b2)/(8*sigma))

    ksigma1 *= 1/(8*3.141592*sigma)
    return ksigma1, 1

def dsigma1(point_cloud, point_cloud2, dgm, dgm2):
    k12, gotloss = ksigma1(point_cloud, point_cloud2, dgm, dgm2)
    if gotloss == 0: return 0, 0
    # if both dgm and dgm2 have at least 1 point:
    k11, gotloss = ksigma1(point_cloud, point_cloud, dgm, dgm)
    return k11 + (-2.) * k12, 1

"""3-scaled gaussian density estimator: (parameters: )"""

def density(point_cloud, dgm, sigma, scale, x):
  tot = 0
  density_x = 0 #density at x
  for i in range(len(dgm['dgms'][0])-1):
    p1, p2 = point_cloud[dgm['gens'][0][i][1]], point_cloud[dgm['gens'][0][i][2]] #pt (0,d) with d=dist(p1,p2) (euclidean dist)
    d = dist(p1, p2) #pt of pt cloud is (0,d)
    density_x += d**3 * torch.exp(-((d-x)/sigma)**2)

  return density_x * scale

def loss_density(point_cloud, point_cloud2, dgm, dgm2, sigma, scale, maxrange, npoints, plot): #dgm of deg0
  xs = np.linspace(0., maxrange, npoints)
  loss = 0
  ## compute difference between both functions in 100 pts (those given by xs)
  dens=[]
  dens0=[]
  for x in xs:
    dx = density(point_cloud, dgm, sigma, scale, x)
    d0x = density(point_cloud2, dgm2, sigma, scale, x)
    loss += (dx - d0x)**2
    if plot:
      with torch.no_grad():
        dens.append(dx.detach().numpy())
        dens0.append(d0x.detach().numpy())

  if plot: #plot both density functions (blue: the one of dgm being learned)
    plt.plot(xs, dens, color='blue')
    plt.plot(xs, dens0, color='red')
    plt.show()

  return loss

## use: sigma=0.2, scale=0.002, maxrange=35., npoints=100

"""Persistent entropy (from dgms of degrees 0 and 1):"""

def loss_persentropy0(point_cloud, dgm, dgm2): #dgm of deg0
  L = 0
  for i in range(len(dgm['dgms'][0])-1): L += dist(point_cloud[dgm['gens'][0][i][1]], point_cloud[dgm['gens'][0][i][2]])
  pers = 0
  for i in range(len(dgm['dgms'][0])-1):
    p1, p2 = point_cloud[dgm['gens'][0][i][1]], point_cloud[dgm['gens'][0][i][2]] #pt (0,d) with d=dist(p1,p2) (euclidean dist)
    d = dist(p1, p2) #pt of pt cloud is (0,d)
    pers += d * torch.log(d/L)

  ##get pers entropy of dgm2:
  L2 = 0
  pers2 = 0
  for i in range(len(dgm2['dgms'][0])-1): L2 += dgm2['dgms'][0][i][1]
  for i in range(len(dgm2['dgms'][0])-1): pers2 += dgm2['dgms'][0][i][1] * math.log(dgm2['dgms'][0][i][1] / L2)

  return (pers/L - pers2/L2)**2

def loss_persentropy1(point_cloud, dgm, dgm2): #dgm of deg1. returns loss, got_loss (0 if did not get it)
  if len(dgm['dgms'][1])==0 or len(dgm2['dgms'][1])==0: return 0, 0 #no loss if dgm has no off-diag points

  #entropy of dgm:
  L = 0
  for i in range(len(dgm['dgms'][1])):
        # pt in dgm: (b1,d1), with b1, d1 = dist(p2, p1), dist(dist(p3, p4)
        p1, p2, p3, p4 = point_cloud[dgm['gens'][1][0][i][0]], point_cloud[dgm['gens'][1][0][i][1]], point_cloud[dgm['gens'][1][0][i][2]], point_cloud[dgm['gens'][1][0][i][3]]
        b1 = dist(p1,p2)
        d1 = dist(p3,p4)
        L += d1 - b1
  pers = 0
  for i in range(len(dgm['gens'][1])):
        # pt in dgm: (b1,d1), with b1, d1 = dist(p2, p1), dist(dist(p3, p4)
        p1, p2, p3, p4 = point_cloud[dgm['gens'][1][0][i][0]], point_cloud[dgm['gens'][1][0][i][1]], point_cloud[dgm['gens'][1][0][i][2]], point_cloud[dgm['gens'][1][0][i][3]]
        b1 = dist(p1,p2)
        d1 = dist(p3,p4)
        pers += (d1-b1) * torch.log((d1-b1)/L)

  #entropy of dgm2:
  L2 = 0
  for i in range(len(dgm2['dgms'][1])):
        L2 += dgm2['dgms'][1][i][1] - dgm2['dgms'][1][i][0]
  pers2 = 0
  for i in range(len(dgm2['gens'][1])):
        lifespan = dgm2['dgms'][1][i][1] - dgm2['dgms'][1][i][0]
        pers += lifespan * torch.log(lifespan/L)
  if len(dgm2['dgms'][1])==0: L2 = 1

  return (pers/L - pers2/L2)**2, 1

"""Example of use in a simple example

To make a gif of evolution:
"""

!pip install pillow

import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
from IPython.display import Image as IPImage

def plot_pc_gif(point_cloud):
    fig = plt.figure(figsize=(6, 6))
    plt.scatter(point_cloud[:, 0], point_cloud[:, 1], s=10, c='b')
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title('Point Cloud')
    plt.xlim(-20, 50)  # Adjust the limits as per your point cloud data
    plt.ylim(-50, 50)  # Adjust the limits as per your point cloud data
    plt.close(fig)
    return fig

def generate_gif(point_clouds, name):
    # Create a list of figures for each point cloud
    figures = [plot_pc_gif(point_cloud) for point_cloud in point_clouds]

    # Save each figure as an image and store them in a list
    images = []
    for idx, fig in enumerate(figures):
        fig.savefig(f'point_cloud_{idx}.png', dpi=80)
        images.append(Image.open(f'point_cloud_{idx}.png'))

    # Save the images as a GIF
    images[0].save(name, save_all=True, append_images=images[1:], duration=200, loop=0)

    # Display the GIF
    IPImage(name)

#to use it:
#generate_gif(point_clouds)

from IPython.display import Image as Image_IPython, display

def display_gif(filename):
    display(Image_IPython(filename))

# Provide the filename of the generated GIF
gif_filename = 'point_clouds_evolution.gif'

# Display the GIF:
#display_gif(gif_filename)

#!apt-get install -y imagemagick

"""First, generate a snythetic ground truth point cloud with dgm:"""

## create ground truth dgm2:
# Plot the point cloud
point_cloud2 = tadasets.dsphere(d=1, n=100, noise=0.0)
fig = go.Figure(plot_point_cloud(point_cloud2))
fig.show()
dgm2 = ripser_parallel(point_cloud2, maxdim=1, return_generators=True)
plot_dgm(dgm2, 1)
point_cloud2 = torch.tensor(point_cloud2, dtype=torch.float32)

## create the learnable pt cloud and train:
number_of_iterations = 20000
number_of_points = 128
n_iters_forplot = 50
point_clouds = []
losses = []

newdata = np.zeros((number_of_points,2))
r1 = 2.
for i in range(0,10):
  newdata[i][0] = random.uniform(-r1, r1)
  newdata[i][1] = random.uniform(-r1, r1)
for i in range(10,20):
  newdata[i][0] = random.uniform(-r1, r1)+10.
  newdata[i][1] = random.uniform(-r1, r1)
for i in range(20,30):
  newdata[i][0] = random.uniform(-r1, r1)
  newdata[i][1] = random.uniform(-r1, r1)+20
for i in range(30,40):
  newdata[i][0] = random.uniform(-r1, r1)+30
  newdata[i][1] = random.uniform(-r1, r1)+30
for i in range(40, number_of_points):
  newdata[i][0] = random.uniform(-r1, r1)+10
  newdata[i][1] = random.uniform(-r1, r1)-25

point_cloud = torch.tensor(newdata, dtype=torch.float32, requires_grad=False)

# plot the initial dgm:
dgm_i = ripser_parallel(newdata, maxdim=1, return_generators=True)
plot_dgm(dgm_i, 1)

point_cloud.requires_grad = True
point_clouds.append(np.copy(point_cloud.detach().numpy()))
optimizer = torch.optim.Adam([point_cloud], lr=0.05)

#plot initial point cloud:
fig = go.Figure(plot_point_cloud(point_clouds[-1]))
fig.show()

for i in range(number_of_iterations):

    dgm = get_dgm(point_cloud, 1)

    ## use here any loss function (or combination of loss functions):
    loss1, gotloss = d_bottleneck1(point_cloud, dgm, dgm2)
    if gotloss: loss = loss1
    loss, gotloss = d_bottleneck0(point_cloud, dgm, dgm2)
    if gotloss == 0: loss = push0(point_cloud, dgm)
    loss1, gotloss = d_bottleneck1(point_cloud, dgm, dgm2)
    if gotloss: loss += loss1

    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
    if (i<1000 and i%200==0): point_clouds.append(np.copy(point_cloud.detach().numpy()))
    if (i% n_iters_forplot==0): point_clouds.append(np.copy(point_cloud.detach().numpy()))

    if (i+1) % n_iters_forplot == 0:
        print(f"Iteration {i + 1}/{number_of_iterations}, Loss: {loss.item()}")
        fig = go.Figure(plot_point_cloud(point_clouds[-1]))
        fig.show()
        # plot dgm of latest point cloud:
        plot_dgm(ripser_parallel(point_clouds[-1], maxdim=1, return_generators=True), 1)
        with torch.no_grad(): losses.append(loss.item())

plt.plot(np.arange(len(losses)), losses)
plt.xlabel(f"Iteration (/{n_iters_forplot})")
plt.ylabel("Loss")
plt.show()

generate_gif(point_clouds, 'pc_evolution_test.gif')
display_gif('pc_evolution_test.gif')

'''
Examples of use:

#to use both bottleneck dists:
loss, gotloss = d_bottleneck0(point_cloud, dgm, dgm2)
if gotloss == 0: loss = push0(point_cloud, dgm)
loss1, gotloss = d_bottleneck1(point_cloud, dgm, dgm2)
if gotloss: loss += loss1

loss, gotloss = d_bottleneck0(point_cloud, dgm, dgm2)
if gotloss == 0: loss = push0(point_cloud, dgm)

loss, gotloss = d_bottleneck1(point_cloud, dgm, dgm2)
if gotloss == 0: loss = push1(point_cloud, dgm)

loss = dsigma0(point_cloud, point_cloud2, dgm, dgm2)
loss1, gotloss = dsigma1(point_cloud, point_cloud2, dgm, dgm2)
if gotloss==1: loss += loss1

loss_density(point_cloud, point_cloud2, dgm, dgm2, 0.2, 0.002, 2., 30, False)

loss = loss_persentropy0(point_cloud, dgm, dgm2)
loss1, gotloss = loss_persentropy1(point_cloud, dgm, dgm2)
if gotloss: loss += loss1
'''
